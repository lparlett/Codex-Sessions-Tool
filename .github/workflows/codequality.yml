# yaml-language-server: $schema=https://json.schemastore.org/github-workflow.json
name: CI
# Updated workflow for code quality checks

permissions:
  contents: read
  pull-requests: write
  id-token: write
  
on:
  workflow_dispatch:
  push:
    branches:
      - main
      - release/**
      - feature/**
  pull_request:
    branches:
      - main
      - release/**

jobs:
  quality:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.12"
      - name: Cache pip packages
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pylint pytest pytest-cov bandit black mypy tomli types-psycopg2
          pip install -e .
      - name: Lint with pylint
        run: pylint --rcfile=.pylintrc $(git ls-files '*.py') || exit $(($? & 35))
      - name: Check formatting with black
        run: black --check --diff .
      - name: Static type checks with mypy
        run: mypy --config-file mypy.ini src cli
      - name: Security scan with bandit
        run: bandit -r src cli
      - name: Ensure default output directories
        run: |
          mkdir -p reports
      - name: Run tests with pytest
        run: |
          pytest tests/ --cov=src --cov=cli --cov-report=xml:coverage.xml --cov-report=term
          ls -la  # Debug: List files to verify coverage.xml was created
      - name: Verify coverage artifact exists
        run: |
          if [ ! -s coverage.xml ]; then
            echo "coverage.xml missing or empty; ensure pytest --cov generated it"
            ls -la
            exit 1
          fi
      - name: Upload coverage reports
        env:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}
        uses: codecov/codecov-action@v5
        with:
          files: ./coverage.xml
          fail_ci_if_error: true
          codecov_yml_path: ./codecov.yml
          verbose: true

  migration-sample:
    if: github.event_name == 'pull_request'
    runs-on: ubuntu-latest
    needs: quality
    services:
      postgres:
        image: postgres:17
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: ai_log_trail
        ports:
          - 5432:5432
        options: >-
          --health-cmd "pg_isready -U postgres"
          --health-interval 5s
          --health-timeout 5s
          --health-retries 5
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.12"
      - name: Install migration dependencies
        run: |
          python -m pip install --upgrade pip
          pip install ".[postgres]"
      - name: Create sample SQLite database
        run: |
          python - <<'PY'
          from pathlib import Path
          import sqlite3
          from src.services.database import ensure_schema

          sqlite_path = Path("sample.sqlite")
          conn = sqlite3.connect(sqlite_path)
          ensure_schema(conn)

          cur = conn.execute("INSERT INTO files (path) VALUES (?)", ("sample.jsonl",))
          file_id = cur.lastrowid
          conn.execute(
              "INSERT INTO sessions (file_id, session_id, raw_json) VALUES (?, ?, ?)",
              (file_id, "sess-1", '{"events": []}'),
          )
          conn.execute(
              "INSERT INTO prompts (file_id, prompt_index, timestamp, message, raw_json) VALUES (?, ?, ?, ?, ?)",
              (file_id, 1, "t0", "Hello", '{"payload": {}}'),
          )
          conn.execute(
              "INSERT INTO events (file_id, timestamp, event_type, category, priority, raw_json) VALUES (?, ?, ?, ?, ?, ?)",
              (file_id, "t0", "event_msg", "test", "low", '{"payload": {}}'),
          )
          conn.commit()
          conn.close()
          PY
      - name: Migrate sample to Postgres
        env:
          POSTGRES_DSN: postgresql://postgres:postgres@localhost:5432/ai_log_trail
        run: |
          python -m cli.migrate_sqlite_to_postgres --sqlite sample.sqlite --postgres-dsn "$POSTGRES_DSN" --execute
      - name: Verify migrated counts
        env:
          POSTGRES_DSN: postgresql://postgres:postgres@localhost:5432/ai_log_trail
        run: |
          python - <<'PY'
          import psycopg2

          dsn = "$POSTGRES_DSN"
          with psycopg2.connect(dsn=dsn) as conn, conn.cursor() as cur:
              for table, expected_min in (("files", 1), ("sessions", 1), ("prompts", 1), ("events", 1)):
                  cur.execute(f"SELECT COUNT(*) FROM {table}")
                  count = cur.fetchone()[0]
                  if count < expected_min:
                      raise SystemExit(f"{table} count {count} < {expected_min}")
          PY
