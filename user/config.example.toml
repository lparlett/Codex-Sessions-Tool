# AI Log Trail Configuration
# Copy this file to config.toml and customize for your environment

# Sessions root (required)
[sessions]
root = "C:/Users/<you>/.codex/sessions"  # Path to Codex/Copilot logs (adjust as needed)

# Ingest settings
[ingest]
batch_size = 1000  # Events to process per batch
db_path = "reports/session_data.sqlite"  # Default SQLite database path (parent must exist)
max_workers = 4  # Max concurrent parsers

# Database backend (SQLite by default). For Postgres, set backend and DSN.
[database]
backend = "sqlite"  # "sqlite" or "postgres"
# sqlite_path = "reports/session_data.sqlite"  # Optional override for SQLite path
# postgres_dsn = "postgresql://user:pass@host:5432/ai_log_trail"  # Required if backend=postgres
# Note: Postgres support requires installing the optional extra: pip install .[postgres]

# Agent-specific configurations
[agents.codex]
type = "codex"
root = "/path/to/.codex/sessions"  # Path to Codex logs
features = { streaming = true, function_calls = true, tool_usage = true }

[agents.copilot]
type = "copilot"
root = "/path/to/.copilot/logs"  # Path to Copilot logs
features = { streaming = false, function_calls = true, tool_usage = true }

[agents.claude]
type = "claude"
root = "/path/to/claude/logs"  # Path to Claude logs
features = { streaming = true, function_calls = true, context_window = true }

# Optional: Agent-specific ingest settings
[agents.codex.ingest]
batch_size = 2000  # Override global batch size
preserve_raw = true  # Keep raw JSON

[export]
redact_secrets = true  # Auto-redact potential secrets
max_content_length = 1000000  # Max event content size

[outputs]
reports_dir = "reports"  # Directory for generated reports (must exist and be writable)
